---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

{% if author.googlescholar %}
  You can also find my articles on <u><a href="{{author.googlescholar}}">my Google Scholar profile</a>.</u>
{% endif %}

{% include base_path %}

- Yujun Huang, Bin Chen, Naiqi Li, and Shu-Tao Xia, Measurement-Bounds-based Rate-Adaptive Image Compressed Sensing, submitted to IEEE Transactions on Signal Processing (TSP).
> Conventional compressed sensing (CS) algorithms typically set the same sampling rate for different image blocks. A potentially more reasonable strategy would be to adaptively allocate the number of measurements based on the complexity of each image block. In this paper, we propose the Measurement-Bounds-based Rate-Adaptive Image Compressed Sensing (MB-RAICS), aiming to adaptively determine the sampling ratio for each image block according to the traditional measurement bounds theory. Additionally, given the scenario where statistical information about the original image cannot be directly obtained in real-world applications, we propose a multi-stage rate-adaptive sampling strategy. This strategy determines the sampling ratio allocation for the next step based on previous sampling information during the step-by-step sampling process. We model the problem of multi-stage rate-adaptive sampling as a convex optimization problem and solve it using Newton's method and binary search. Finally, we incorporate skip connections between successive iterations at the decoding end to ensure more thorough cross-iteration transmission of feature information. Experiments show that our proposed method outperforms state-of-the-art methods, and the effectiveness of each proposed module is also validated.

- Naiqi Li*, Wenjie Li*, Yinghua Gao, Yiming Li, Jigang Bao, Ercan E. Kuruoglu, Yong Jiang and Shu-Tao Xia, Node-level Graph Regression with Deep Gaussian Process Models, submitted to IEEE Transactions on Artificial Intelligence.
> In this paper, we study node-level graph regression, which aims to predict an output vector for each node on a given graph. This task has a broad range of applications, including spatio-temporal forecasting and computational biology. We propose a model called Deep Gaussian Processes over Graphs (DGPG), which is composed of hierarchical Gaussian processes and learns the mapping between input-output signals in graph domains. DGPG possesses several distinctive advantages, such as the ability in capturing uncertainty, effectiveness on small datasets, and requiring fewer efforts for selecting model architectures and hyperparameters. It is also more favorable than traditional Gaussian process models in terms of expressiveness and scalability, due to the hierarchical deep structure and the variational inference framework. Moreover, we generalize DGPG to a more challenging setting where the graph structure is time-varying. Our theoretical analysis shows that the graph information can improve convergence by reducing sampling variances when optimizing the evidence lower bound, and the challenge of time-varying graph structure can be addressed by a time-weighted sampling scheme. The performance of DGPG is demonstrated through extensive experiments in various synthetic and real-world datasets. Some appealing characteristics of DGPG are further discussed, such as its ability to capture prediction uncertainty and learn graph structures.

- Naiqi Li, Yuqiu Xie, Tao Dai, Jiawei Li, Bin Chen, Yong Jiang and Shu-Tao Xia, Efficient Differentiable Approximation of the Generalized Low-rank Regularization, submitted to the International Conference on Learning Representations (ICLR-24).
> Low-rank regularization (LRR) has been widely applied in various machine learning tasks, but the associated optimization is challenging. Directly optimizing the rank function under constraints is NP-hard in general. To overcome this difficulty, various relaxations of the rank function were studied. However, optimization of these relaxed LRRs typically depends on singular value decomposition, which is a time-consuming and nondifferentiable operator that cannot be optimized with gradient-based techniques. To address these challenges, in this paper we propose an efficient differentiable approximation of the generalized LRR. The considered LRR form subsumes many popular choices like the nuclear norm, the Schatten-$p$ norm, and various nonconvex relaxations. Our method enables LRR terms to be appended to loss functions in a plug-and-play fashion, and be conveniently optimized by off-the-shelf machine learning libraries.
Furthermore, the proposed approximation solely depends on matrix multiplication, which is a GPU-friendly operation that enables efficient parallel implementation. In the experimental study, the proposed method is applied to various tasks, which demonstrates its versatility and efficiency.

- Tao Dai, Beiliang Wu, Peiyuan Liu, Naiqi Li, Jigang Bao, Yong Jiang and Shu-Tao Xia, Periodicity Decoupling Framework for Long-term Series Forecasting, submitted to the International Conference on Learning Representations (ICLR-24).
> Convolutional neural network (CNN)-based and Transformer-based methods have recently made significant strides in time series forecasting, which excel at modeling local temporal variations or capturing long-term dependencies. we propose a novel Periodicity Decoupling Framework (PDF) to capture 2D temporal variations of decoupled series for long-term series forecasting. Our PDF mainly consists of three components: multi-periodic decoupling block (MDB), dual variations modeling block (DVMB), and variations aggregation block (VAB). Unlike the previous methods that model 1D temporal variations, our PDF mainly models 2D temporal variations, decoupled from 1D time series by MDB. After that, DVMB attempts to further capture short-term and long-term variations, followed by VAB to make final predictions. Extensive experimental results across seven real-world long-term time series datasets demonstrate the superiority of our method over other
state-of-the-art methods, in terms of both forecasting performance and computational efficiency.

- Jiarui Yang, Yufei Zhu, Naiqi Li, Jinmin Li, Tao Dai and Shu-Tao Xia, Conditional Mask Guided Diffusion Prior Interpolation for Consistent Face Super-Resolution, submitted to The IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR-24).
> Diffusion models with exceptional generation capability and scalability have recently achieved remarkable performance in face super-resolution (FSR). However, most existing diffusion-based works still suffer from the problems of visual consistency, i.e., the reconstructed images are not visually consistent with the ground truth (GT) images. To address this issue, we propose a novel Conditional Mask Guided Diffusion Prior Interpolation method (DPI) that employs a masking strategy on the posterior distribution of a pre-trained diffusion model with rich priors, ensuring a balanced output of diverse yet consistent results in FSR. Specifically, the diffusion sampling process is divided into two stages, with each stage involving condition refinement. In the first stage, we utilize the diffusion prior to interpolate Fixed Conditional Masks (FCMs) for generating consistent facial contour features. In the second stage, we enhance fidelity by employing Random Adaptive Conditional Masks (RACMs), which provide semantic guidance. We evaluate DPI on 4×, 8×, 16× super-resolution task on CelebA 1000 where DPI achieves higher image similarity and sample quality (LPIPS and FID) than state-of-the-art diffusion-based methods, which validate DPI's effectiveness in guiding the diffusion model.

- Shiqi Dai, Xuanyu Zhu, Naiqi Li, Tao Dai and Zhi Wang, Procedural Level Generation with Diffusion Models from a Single Example, submitted to AAAI Conference on Artificial Intelligence (AAAI-24).
> Level generation is a central focus of Procedural Content Generation (PCG), yet deep learning-based approaches are limited by scarce training data, i.e., human-designed levels. Despite being a dominant framework, Generative Adversarial Networks (GANs) exhibit a substantial quality gap between generated and human-authored levels, alongside rising training costs, particularly with increasing token complexity. In this paper, we introduce a diffusion-based generative model that learns from just one example. Our approach involves two core components: 1) an efficient yet expressive level representation, and 2) a latent denoising network with constrained receptive fields. To start with, our approach employs token semantic labels akin to word embeddings for dense representations, surpassing one-hot encoding in accommodating larger levels but also enhancing stability and faster convergence in latent diffusion. In addition, we adapt the denoising network architecture to confine the receptive field to localized patches of the data, aiming to facilitate single-example learning. Extensive experiments demonstrate that our model is capable of generating stylistically congruent samples of arbitrary sizes compared to manually designed levels. It suits a wide range of level structures with fewer artifacts than GAN-based approaches.

- Peiyuan Liu, Beiliang Wu, Naiqi Li, Tao Dai, Fengmao Lei, Jigang Bao, Yong Jiang and Shu-Tao Xia, WFTNet: Exploiting Global and Local Periodicity in Long-term Time Series Forecasting, submitted to IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP-24). 
> Recent CNN and Transformer-based models tried to utilize frequency and periodicity information for long-term time series forecasting. However, most existing work is based on Fourier transform, which cannot capture fine-grained and local frequency structure. In this paper, we propose a Wavelet-Fourier Transform Network (WFTNet) for long-term time series forecasting. WFTNet utilizes both Fourier and wavelet transforms to extract comprehensive temporal-frequency information from the signal, where Fourier transform captures the global periodic patterns and wavelet transform captures the local ones. Furthermore, we introduce a Periodicity-Weighted Coefficient (PWC) to adaptively balance the importance of global and local frequency patterns. Extensive experiments on various time series datasets show that WFTNet consistently outperforms other state-of-the-art baseline.

- Xiang Liu, Bin Chen, Naiqi Li, Tao Dai, Jigang Bao, Yong Jiang and Shu-Tao Xia, H-ROCKET: Evolutionary Rocket With Hybrid Kernels for Fast Time Series Classification, submitted to IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP-24). 
> In this paper, we propose a novel time series classification method called evolutionary hybrid kernels ROCKET (H-ROCKET), which is based on the recently proposed ROCKET model that uses a large number of random convolutional kernels as feature extractors. Our approach adds another two types of kernel to improve  model's feature extraction capability. The evolutionary algorithm is used to explore different combinations of active kernels, which reduces the number of kernels in the final model as well as the computational cost. Furthermore, we propose the group-wise crossover operation so that good partial solution can be preserved, and improve the fitness function to encourage kernel sparsity and avoid overfitting. Thorough experiments show that H-ROCKET can significantly improve computational efficiency while maintaining classification accuracy.

- Bolin Jiang, Yuqiu Xie, Jiawei Li, Naiqi Li, Yong Jiang and Shu-tao Xia, Generation and Fusion: Augmenting Datasets for Image Anomaly Detection via Latent Diffusion Model, submitted to IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP-24). 
> Data augmentation has been widely applied in anomaly detection, which generates synthetic anomalous data for training. However, most existing anomaly augmentation methods focus on image-level cut-and-paste techniques, resulting in less realistic synthetic results, and are restricted to a few predefined patterns. In this paper, we propose our Controllable Anomaly Generator (CAGen) for anomaly data augmentation, which can generate high-quality images, and be flexibly controlled with text prompts. Specifically, our method fine-tunes a ControlNet model by using binary masks and textual prompts to control the spatial localization and style of generated anomalies. To further augment the resemblance between the generated features and normal samples, we propose a fusion method that integrates the generated anomalous features with the features of normal samples. Experiments on standard anomaly detection benchmarks show that the proposed data augmentation method significantly leads to a 0.4/3.1 improvement in the AUROC/AP metric.

- Yuqiu Xie, Bolin Jiang, Jiawei Li, Naiqi Li, Yong Jiang and Shu-tao Xia, DiffuseQR: Stylized QR Code Generation, submitted to IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP-24). 
> Traditional QR codes consist of a grid of black-and-white square modules, which lack aesthetic appeal and meaning for human perception. This has motivated recent research to enhance the visual quality of QR codes. However, early efforts primarily relied on predefined rules and styles, limiting their flexibility and controllability.
In this paper, we introduce a novel approach for stylized QR code generation called DiffQR, which leverages the framework of Stable Diffusion, two newly trained ControlNet models, and a scanning-robustness module. DiffQR allows us to create stylized QR codes that seamlessly blend the code with content from blended images and text prompts. Our experiments demonstrate that  our method can generate stylized QR code with appealing perception details, while maintaining robust scanning reliability.

- Xinyi Zhang, **Naiqi Li**, Jiawei Li, Tao Dai, Yong Jiang and Shu-Tao Xia, Unsupervised Surface Anomaly Detection with Diffusion Probabilistic Model, Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV-23), 2023.
> Unsupervised surface anomaly detection aims at discovering and localizing anomalous patterns using only anomaly-free training samples. Reconstruction-based models are among the most popular and successful methods, which rely on the assumption that anomaly regions are more difficult to reconstruct. However, there are three major challenges to the practical application of this approach: 1) the reconstruction quality needs to be further improved since it has a great impact on the final result, especially for images with structural changes; 2) it is observed that for many neural networks, the anomalies can also be well reconstructed, which severely violates the underlying assumption; 3) since reconstruction is an ill-conditioned problem, a test instance may correspond to multiple normal patterns, but most current reconstruction-based methods have ignored this critical fact. In this paper, we propose DiffAD, a method for unsupervised anomaly detection based on the latent diffusion model, inspired by its ability to generate high-quality and diverse images. We further propose noisy condition embedding and interpolated channels to address the aforementioned challenges in the general reconstruction-based pipeline. Extensive experiments show that our method achieves state-of-the-art performance on the challenging MVTec dataset, especially in localization accuracy.

- **Naiqi Li**, Zhikang Xia, Yiming Li, Ercan E. Kuruoglu, Yong Jiang and Shu-Tao Xia, Portfolio Selection via Graph-aware Gaussian Process Regression with Generalized Gaussian Likelihood, IEEE Transaction on Artificial Intelligence, 2023.
> Abstract: Portfolio selection aims to manage the allocation of wealth among different assets, which remains to be a fundamental and challenging financial task. Markowitz's mean-variance analysis is one of the most well-known and widely adopted techniques for this problem. However, it requires accurate estimations of both the mean and variance of the return, while predicting the variance is particularly difficult. In this paper, we propose a novel portfolio selection strategy based on a graph-aware Gaussian process model equipped with generalized Gaussian distribution likelihood. Our method unleashes the potential of mean-variance analysis by exploiting the Gaussian process model's ability in capturing uncertainty, and the graph information is also incorporated so that correlation among different assets can be utilized. We notice that most existing financial models assume the returns follow the log-normal distribution, whereas we observe that it cannot perfectly explain real-world market data. Based on this discovery, we introduce the generalized Gaussian distribution as the likelihood function. We further improve our method by proposing a passive variant to address transaction fees, and designing the mean function of the Gaussian process with the mean reversion principle. Thorough experiments were performed on synthetic and real-world financial datasets to verify the effectiveness of our method. 

- Guanghao Meng, Tao Dai, Bin Chen, **Naiqi Li**, Yong Jiang and Shu-Tao Xia, Difficulty-Aware Data Augmentor for Scene Text Recognition, In International Conference on Acoustics, Speech and Signal Processing (ICASSP-23), 2023. 
- **Naiqi Li** *, Wenjie Li *, Yong Jiang and Shu-Tao Xia, Deep Dirichlet Process Mixture Models. In Conference on Uncertainty in Artificial Intelligence (UAI-22), 2022.

- Lu Si, **Naiqi Li**, Tongyu Huang, Shan Du, Yang Dong, Yue Yao, Hui Ma, Computational image translation from Mueller matrix polarimetry to bright-field microscopy. Journal of Biophotonics, 2021.

- Lu Si, **Naiqi Li**, Shan Du, Yang Dong, Shaoxiong Liu, and Hui Ma, Computational Immunohistochemistry Staining on Lung Tissues based on Mueller Matrix Microscopy. In Proceedings of Polarized Light and Optical Angular Momentum for Biomedical Diagnostics, 2021.

- **Naiqi Li**, Yinghua Gao, Yong Jiang and Shu-Tao Xia, H-GPR: A Hybrid Strategy for Large-Scale Gaussian Process Regression. In International Conference on Acoustics, Speech and Signal Processing (ICASSP-21), 2021. 

- Xiang Liu, **Naiqi Li**, Shu-Tao Xia, GDTW: A Novel Differentiable DTW Loss For Time Series Tasks. In International Conference on Acoustics, Speech and Signal Processing (ICASSP-21), 2021. 

- **Naiqi Li** *, Wenjie Li *, Jifeng Sun, Yinghua Gao, Yong Jiang and Shu-Tao Xia, Stochastic Deep Gaussian Processes over Graphs. In Advances in Neural Information Processing Systems (NeurIPS-20), 2020. 

- Yinghua Gao *, **Naiqi Li** *, Ning Ding, Yiming Li, Tao Dai and Shu-Tao Xia, Generalized Local Aggregation for Large Scale Gaussian Process Regression. In the International Joint Conference on Neural Networks (IJCNN-20), 2020.

- Peiming Mo, **Naiqi Li** and Yongmei Liu. Automatic Verification of Golog Programs via Predicate Abstraction. In Proceedings of the 22nd European Conference on Artificial Intelligence (ECAI-16), 2016. 

- **Naiqi Li** and Yongmei Liu. Automatic Verification of Partial Correctness of Golog Programs. In Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI-15), 2015. 

- **Naiqi Li**, Yi Fan and Yongmei Liu. Reasoning about State Constraints in the Situation Calculus. In Proceedings of the 23rd International Joint Conference on Artificial Intelligence (IJCAI-13), 2013. 

- Yi Fan, Minghui Cai, **Naiqi Li**, Yongmei Liu. A First-Order Interpreter for Knowledge-Based Golog with Sensing based on Exact Progression and Limited Reasoning. In Proceedings of the 26th AAAI Conference on Artificial Intelligence (AAAI-12), 2012. 

  (* indicates equal contributions)